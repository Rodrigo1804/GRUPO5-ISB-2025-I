# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nIvuczPQvfjTbOZDKxU-Km5UT9760IxT
"""

!pip install neurokit2

import neurokit2 as nk
import matplotlib.pyplot as plt
import numpy as np

ti1 = np.array((-70, -15, 0, 15, 100))
# a, the amplitude of each spike
ai1 = np.array((1.2, -5, 30, -7.5, 0.75))
# b, the width of each spike
bi1 = np.array((0.25, 0.1, 0.1, 0.1, 0.4))

# Add noise
# ===============
ti1 = np.random.normal(ti1, np.ones(5) * 3)
ai1 = np.random.normal(ai1, np.abs(ai / 5))
bi1 = np.random.normal(bi1, np.abs(bi / 5))

ti2 = np.array((-60, -10, 0, 10, 90))
# a, the amplitude of each spike
ai2 = np.array((2.1, -3, 20, -10, 1))
# b, the width of each spike
bi2 = np.array((1, 0.1, 0.1, 0.5, 1.5))

# Add noise
# ===============
ti2 = np.random.normal(ti2, np.ones(5) * 3)
ai2 = np.random.normal(ai2, np.abs(ai2 / 5))
bi2 = np.random.normal(bi2, np.abs(bi2 / 5))

ecg1 = nk.ecg_simulate(duration=20, sampling_rate=1000, heart_rate=70, method="ecgsyn", ti=ti1, ai=ai2, bi=bi2)
ecg2 = nk.ecg_simulate(duration=20, sampling_rate=1000, heart_rate=90, method="ecgsyn", ti=ti2, ai=ai2, bi=bi2)

# Add noise
# ===============
ti = np.random.normal(ti, np.ones(5) * 3)
ai = np.random.normal(ai, np.abs(ai / 5))
bi = np.random.normal(bi, np.abs(bi / 5))

fs = 1000  # frecuencia de muestreo
n_samples = len(ecg1)
t = np.linspace(0, n_samples / fs, n_samples)


plt.subplot(2, 1, 1)
plt.plot(t, ecg1, label="ECG 1 - 70 bpm")
plt.title("ECG 1 - Ritmo simulado (70 latidos por minuto)")
plt.xlabel("Tiempo (s)")
plt.ylabel("Amplitud")
plt.grid(True)

plt.subplot(2, 1, 2)
plt.plot(t, ecg2, label="ECG 2 - 90 bpm")
plt.title("ECG 2 - Ritmo simulado (90 latidos por minuto)")
plt.xlabel("Tiempo (s)")
plt.ylabel("Amplitud")
plt.grid(True)

plt.tight_layout()
plt.show()

from scipy.stats import skew, kurtosis

# Calcular características estadísticas
mean_ecg = np.mean(ecg1)
median_ecg = np.median(ecg1)
kurtosis_ecg = kurtosis(ecg1)
skewness_ecg = skew(ecg1)
energy_ecg = np.sum(ecg1)

# Imprimir las características
print(f"Mean: {mean_ecg}")
print(f"Median: {median_ecg}")
print(f"Kurtosis: {kurtosis_ecg}")
print(f"Skewness: {skewness_ecg}")
print(f"Energy: {energy_ecg}")

fs = 1000  # frecuencia de muestreo (Hz)
duration = 10  # segundos

np.random.seed(42)  # Para reproducibilidad de los ruidos aleatorios

# (a) ECG “normal” (una sola derivación) mediante ecgsyn
ti0 = np.array((-100, -5, 0, 5, 120))
ai0 = np.array(( 2, -7, 20, -9.5, 2))
bi0 = np.array((1, 0.1,  0.1,  0.1,  2))

# Simulación 1: ECG “single” normal (sin turbear demasiado los parámetros)
ecg_single = nk.ecg_simulate(duration=duration,sampling_rate=fs,heart_rate=70,method="ecgsyn",ti = ti0,ai = ai0,bi = bi0)

# (b) ECG “modificado” (ligera variación de amplitud y ancho)
# Para simular variaciones fisiológicas, añadimos ruido a ti, ai, bi:
ti1 = np.random.normal(ti0, np.ones(5) * 3)
ai1 = np.random.normal(ai0, np.abs(ai0/5))
bi1 = np.random.normal(bi0, np.abs(bi0/5))

ecg_mod = nk.ecg_simulate(
    duration=duration,
    sampling_rate=fs,
    heart_rate=70,
    method="ecgsyn",
    ti = ti1,
    ai = ai1,
    bi = bi1
)

# (c) ECG “anómalo” (QRS ancho + T invertida)
ti2 = np.random.normal(ti0, np.ones(5) * 3)
ai2 = np.random.normal(ai0, np.abs(ai0/5))
bi2 = np.random.normal(bi0, np.abs(bi0/5))
# Forcemos T invertida
ai2[4] = -0.5

# Forzamos QRS ancho aumentando bi2[2] (índice 2 corresponde a la onda R)
bi2[2] = bi2[2] * 2

ecg3 = nk.ecg_simulate(duration=duration,sampling_rate=fs,heart_rate=70,method="ecgsyn",ti = ti2,ai = ai2,bi = bi)

# Ponerlas en una lista para iterar
ecg_signals = [ecg1, ecg2, ecg3]
signal_names = ['ECG1', 'ECG1', 'ECG3']

import pandas as pd

# 1) Iterar sobre cada señal
all_features = []

for i, signal in enumerate(ecg_signals):
    # 2.1) Detectar picos R (para obtener RR)
    # Primero “limpiamos” un poco la señal (aunque ecg_simulate ya sale razonablemente limpio),
    # y luego usamos nk.ecg_peaks para localizar los índices de los R-peaks:
    ecg_cleaned = nk.ecg_clean(signal, sampling_rate=fs, method="biosppy")
    peaks_dict = nk.ecg_peaks(ecg_cleaned, sampling_rate=fs)
    #rpeaks = peaks_dict["ECG_R_Peaks"]  # índices de muestra donde NeuroKit2 detectó cada R
    rpeaks = peaks_dict[0]

    # 2.2) Calcular RR intervals en segundos
    if len(rpeaks) >= 2:
        t_peaks = rpeaks / fs
        rr_intervals = np.diff(t_peaks)  # array de (N_peaks - 1) valores en segundos
        rr_mean = np.mean(rr_intervals)
        rr_std  = np.std(rr_intervals)
    else:
        rr_mean = np.nan
        rr_std  = np.nan

    # 2.3) Estadísticos “básicos” + HOS
    feats = {
        'Signal_Type'       : signal_names[i],
        'Mean'              : np.mean(signal),
        'Median'            : np.median(signal),
        'STD'               : np.std(signal),
        'Skewness'          : skew(signal),
        'Kurtosis'          : kurtosis(signal, fisher=True),  # fisher=True => kurtosis “exceso” (gaussiana=0)
    #    'RR_Intervals_Mean' : rr_mean,
    #    'RR_Intervals_STD'  : rr_std
    }

    all_features.append(pd.DataFrame([feats]))

# Unir todo en un solo DataFrame
combined_features_df = pd.concat(all_features, ignore_index=True)

print("=== DataFrame con características extraídas ===")
print(combined_features_df)

import matplotlib.pyplot as plt
import seaborn as sns

from scipy.stats import skew, kurtosis
from sklearn.decomposition import PCA

pca_input = combined_features_df.drop(columns=['Signal_Type']).copy()

# 3.1.1) Rellenar NaNs (por seguridad). Aquí se llenan con la media de cada columna.
pca_input = pca_input.fillna(pca_input.mean())

# 3.2) Instanciar y entrenar PCA
pca = PCA(n_components=3)
pca_result = pca.fit_transform(pca_input)  # devuelve matrix (n_signals × 2)

# 3.3) Armamos un DataFrame para graficar
pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2',"PC3"])
pca_df['Signal_Type'] = combined_features_df['Signal_Type']

print("\n=== Resultados PCA (2 dimensiones) ===")
print(pca_df)

plt.figure(figsize=(8, 6))
sns.scatterplot(
    x='PC1',
    y='PC2',
    hue='Signal_Type',
    data=pca_df,
    s=100,
    palette="Set2"
)
plt.title('PCA de Características de ECG (2 Dimensiones)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.grid(alpha=0.3)
plt.legend(title='Tipo de Señal')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(
    x='PC1',
    y='PC3',
    hue='Signal_Type',
    data=pca_df,
    s=100,
    palette="Set2"
)
plt.title('PCA de Características de ECG (2 Dimensiones)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.grid(alpha=0.3)
plt.legend(title='Tipo de Señal')
plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

ecg4 = ecg1   # Clase 0
ecg5 = ecg2   # Clase 1
ecg6 = ecg3  # Clase 2

# Lista de señales y sus etiquetas
signals = [ecg1, ecg2, ecg3, ecg4, ecg5, ecg6]
labels = [0, 1, 2, 0, 1, 2]

# Extraer características: media, std, energía, skewness, kurtosis
features = []
for signal in signals:
    features.append([
        np.mean(signal),
        np.std(signal),
        np.sum(signal**2),
        pd.Series(signal).skew(),
        pd.Series(signal).kurt()
    ])

# Crear DataFrame con las características
df = pd.DataFrame(features, columns=["mean", "std", "energy", "skewness", "kurtosis"])
df["label"] = labels

# Escalar datos y aplicar PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df.drop("label", axis=1))
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Visualizar resultados
plt.figure(figsize=(8, 6))
for label in np.unique(labels):
    plt.scatter(X_pca[np.array(labels) == label, 0],
                X_pca[np.array(labels) == label, 1],
                label=f"Clase {label}")
plt.xlabel("Componente principal 1")
plt.ylabel("Componente principal 2")
plt.title("Separabilidad de señales ECG simuladas (PCA)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Mostrar tabla de características
print(df)